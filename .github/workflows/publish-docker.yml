name: Publish Docker images

on:
  release:
    types: [published]
  workflow_dispatch:

permissions:
  packages: write
  contents: read

    
jobs:

  build-llama-cpp:
    uses: localagi/ai-dedicated-workflows/.github/workflows/operation-docker-build-publish.yml@v3
    with:
      dockerfile: Dockerfile
      context-repository: ggerganov/llama.cpp
      context-repository-ref: ${{ github.ref_name }}
      registry-repo-name: llama.cpp
      tags: |
        type=schedule
        type=ref,event=branch
        type=raw,value=${{ github.ref_name }}
      flavor: |
        suffix=${{ matrix.suffix }}
      build-args: |
        FROM_IMAGE=${{ matrix.from || 'python:3.10-slim-bullseye' }}
        CMAKE_ARGS=${{ matrix.cmake-args }} -DLLAMA_BUILD_SERVER=1
      platforms: ${{ matrix.platforms || 'linux/amd64' }}
    secrets: inherit
    strategy:
      fail-fast: false
      matrix:
        include:
         
        - type: AVX2 # defaults
          platforms: linux/amd64,linux/arm64/v8

        - type: AVX
          suffix: "-avx"
          cmake-args: "-DLLAMA_AVX2=OFF"
          platforms: linux/amd64,linux/arm64/v8                

        - type: AVX512
          suffix: "-avx512"
          cmake-args: "-DLLAMA_AVX512=ON -DBUILD_SHARED_LIBS=ON"
          platforms: linux/amd64,linux/arm64/v8            
          
        - type: CLBLAST
          suffix: "-clblast"
          cmake-args: "-DLLAMA_CLBLAST=ON" # -DCMAKE_PREFIX_PATH="$env:RUNNER_TEMP/clblast"
          platforms: linux/amd64,linux/arm64/v8   

        - type: OPENBLAS
          cmake-args: "-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS"
          suffix: "-openblas"
          platforms: linux/amd64,linux/arm64/v8
          
        # see https://hub.docker.com/r/nvidia/cuda/tags       
        - type: CUBLAS
          suffix: "-cublas-11.7.1" 
          cmake-args: "-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=61;86"
          from: nvidia/cuda:11.7.1-devel-ubuntu22.04
          
        - type: CUBLAS
          suffix: "-cublas-12.1.1"
          cmake-args: "-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=61;86;89"
          from: nvidia/cuda:12.1.1-devel-ubuntu22.04
